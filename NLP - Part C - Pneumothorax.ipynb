{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MIT Tutorial - Part - C - Pneumothorax.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/norikaisa/MIMIC_eICU/blob/master/NLP%20-%20Part%20C%20-%20Pneumothorax.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "kahC0Hi6sX7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pneumothorax example\n",
        "\n",
        "## Sentence tokenization, and spotting term + negation\n",
        "\n",
        "This example spots meantions of the \"pneumothorax\" lexicon in CXR reports and looks at whether the spotted pneumothorax mentioned was negated or not. \n",
        "\n",
        "*Joy Wu* <joy.wu@ibm.com>*, *Daniel Gruhl <dgruhl@us.ibm.com>*"
      ]
    },
    {
      "metadata": {
        "id": "IghAvd9KsX7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Required files\n",
        "import requests\n",
        "from requests.auth import HTTPBasicAuth\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eItuw11H61V2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Authenticate:** The line of code below ensures you are an authenticated user accessing the MIMIC database. You will need to rerun this each time you open the notebook."
      ]
    },
    {
      "metadata": {
        "id": "H30PHyTf2m0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user() #This will allow you to authenticate access to BigQuery"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sRzpINxx7BJY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Query Function: **This is a method that executes a desired SQL query on the database. If you want to run a query, you can use the function name below, which we named run_query()\n"
      ]
    },
    {
      "metadata": {
        "id": "k7Y86QrA2xDy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_id='hst-953-2018'\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"]=project_id\n",
        "# Read data from BigQuery into pandas dataframes.\n",
        "def run_query(query):\n",
        "  return pd.io.gbq.read_gbq(query, project_id=project_id, verbose=False, configuration={'query':{'useLegacySql': False}})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72KosSwasX7p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sentence splitting:"
      ]
    },
    {
      "metadata": {
        "id": "2oVmqJuLsX7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "17e69c4a-5ce4-4034-a636-14a797961f3e"
      },
      "cell_type": "code",
      "source": [
        "# Read the sample CXR reports into a pandas dataframe, and print out a random report\n",
        "#CXRreports = pd.read_csv('mimic3_1000cxrReports.csv')\n",
        "#CXRreports.head()\n",
        "\n",
        "\n",
        "CXRreports = run_query('''\n",
        "SELECT * \n",
        "FROM `hst-953-2018.NLP_workshop.cxr`\n",
        "''')\n",
        "CXRreports.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=495642085510-k0tmvj2m941jhre2nbqka17vqpjfddtd.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fbigquery&state=wXpnzx97A83XVebTu6IBw78jrTw3U4&prompt=consent&access_type=offline\n",
            "Enter the authorization code: 4/dgB6JMxLVND4cErqjYpmoN749zfretTupxmQCwAAXVZvTQaVvMOw3Os\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_id</th>\n",
              "      <th>hadm_id</th>\n",
              "      <th>row_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>256</td>\n",
              "      <td>155415</td>\n",
              "      <td>739694</td>\n",
              "      <td>[**2163-7-27**] 11:44 AM\\n CHEST (PORTABLE AP)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13316</td>\n",
              "      <td>172688</td>\n",
              "      <td>738814</td>\n",
              "      <td>[**2104-2-19**] 4:20 PM\\n CHEST (SINGLE VIEW) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5637</td>\n",
              "      <td>157276</td>\n",
              "      <td>738831</td>\n",
              "      <td>[**2194-3-20**] 11:32 AM\\n CHEST (PORTABLE AP)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22533</td>\n",
              "      <td>145806</td>\n",
              "      <td>741019</td>\n",
              "      <td>[**2182-7-16**] 2:44 PM\\n CHEST (PORTABLE AP) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1287</td>\n",
              "      <td>111856</td>\n",
              "      <td>740821</td>\n",
              "      <td>[**2138-7-26**] 6:49 AM\\n CHEST (PORTABLE AP) ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   subject_id hadm_id  row_id  \\\n",
              "0         256  155415  739694   \n",
              "1       13316  172688  738814   \n",
              "2        5637  157276  738831   \n",
              "3       22533  145806  741019   \n",
              "4        1287  111856  740821   \n",
              "\n",
              "                                                text  \n",
              "0  [**2163-7-27**] 11:44 AM\\n CHEST (PORTABLE AP)...  \n",
              "1  [**2104-2-19**] 4:20 PM\\n CHEST (SINGLE VIEW) ...  \n",
              "2  [**2194-3-20**] 11:32 AM\\n CHEST (PORTABLE AP)...  \n",
              "3  [**2182-7-16**] 2:44 PM\\n CHEST (PORTABLE AP) ...  \n",
              "4  [**2138-7-26**] 6:49 AM\\n CHEST (PORTABLE AP) ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "39aeASmGsX75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "558c7f61-00dd-4298-c7f4-4d5055281f01"
      },
      "cell_type": "code",
      "source": [
        "#This prints a random report\n",
        "report = CXRreports.text[random.randint(0,1000)]\n",
        "print(report)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[**2176-7-10**] 5:34 AM\n",
            " CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 29270**]\n",
            " Reason: eval for CHF/ pulmonary edema\n",
            " ______________________________________________________________________________\n",
            " [**Hospital 4**] MEDICAL CONDITION:\n",
            "  83 year old woman with infected pseudocyst in pancreas, now altered mental\n",
            "  status, bilateral crackles new at bases.\n",
            " REASON FOR THIS EXAMINATION:\n",
            "  eval for CHF/ pulmonary edema\n",
            " ______________________________________________________________________________\n",
            "                                 FINAL REPORT\n",
            " INDICATION:  Rectal pseudocyst. Altered mental status.\n",
            "\n",
            " SINGLE VIEW CHEST:   Comparison is made to prior radiograph of [**2176-7-7**].\n",
            "\n",
            " A central venous line catheter is in the upper SVC.  There has been interval\n",
            " placement of an NG tube which is seen to course to the stomach.  Again\n",
            " demonstrated is a calcified plaque in the left lateral hemithorax.  There is\n",
            " bilateral basilar atelectasis and a right pleural effusion.  The lungs are\n",
            " clear.  There is mild upper zone redistribution.\n",
            "\n",
            " IMPRESSION:\n",
            " 1) Mild upper zone redistribution.  No overt failure.\n",
            " 2) Right effusion with bilateral atelectasis.\n",
            " 3) Densely calcified left lateral pleural plaque.\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1XE_GBgB4f6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0d7d3883-27fd-4559-908f-cf9ace8cbbd5"
      },
      "cell_type": "code",
      "source": [
        "  #This imports nltk and punkt into our environment\n",
        "  >>> import nltk\n",
        "  >>> nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "G7iMxWsUsX8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "31d83d45-2cf5-4222-d969-6cd23cb23ace"
      },
      "cell_type": "code",
      "source": [
        "# Tokenize the sentences with sent_tokenize from NLTK\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "# Alternatively, tokenize with PunktSentenceTokenizer from NLTK if you want to keep track of character offsets of sentences\n",
        "sents = sent_tokenize(report.replace('\\n',' ')) # removing new line breaks\n",
        "# Print out list of sentences:\n",
        "sent_count = 0\n",
        "for s in sents:\n",
        "    print(\"Sentence \" + str(sent_count) +\":\")\n",
        "    print(s)\n",
        "    print()\n",
        "    sent_count = sent_count + 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence 0:\n",
            "[**2176-7-10**] 5:34 AM  CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 29270**]  Reason: eval for CHF/ pulmonary edema  ______________________________________________________________________________  [**Hospital 4**] MEDICAL CONDITION:   83 year old woman with infected pseudocyst in pancreas, now altered mental   status, bilateral crackles new at bases.\n",
            "\n",
            "Sentence 1:\n",
            "REASON FOR THIS EXAMINATION:   eval for CHF/ pulmonary edema  ______________________________________________________________________________                                  FINAL REPORT  INDICATION:  Rectal pseudocyst.\n",
            "\n",
            "Sentence 2:\n",
            "Altered mental status.\n",
            "\n",
            "Sentence 3:\n",
            "SINGLE VIEW CHEST:   Comparison is made to prior radiograph of [**2176-7-7**].\n",
            "\n",
            "Sentence 4:\n",
            "A central venous line catheter is in the upper SVC.\n",
            "\n",
            "Sentence 5:\n",
            "There has been interval  placement of an NG tube which is seen to course to the stomach.\n",
            "\n",
            "Sentence 6:\n",
            "Again  demonstrated is a calcified plaque in the left lateral hemithorax.\n",
            "\n",
            "Sentence 7:\n",
            "There is  bilateral basilar atelectasis and a right pleural effusion.\n",
            "\n",
            "Sentence 8:\n",
            "The lungs are  clear.\n",
            "\n",
            "Sentence 9:\n",
            "There is mild upper zone redistribution.\n",
            "\n",
            "Sentence 10:\n",
            "IMPRESSION:  1) Mild upper zone redistribution.\n",
            "\n",
            "Sentence 11:\n",
            "No overt failure.\n",
            "\n",
            "Sentence 12:\n",
            "2) Right effusion with bilateral atelectasis.\n",
            "\n",
            "Sentence 13:\n",
            "3) Densely calcified left lateral pleural plaque.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xkF7qKoXsX8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "5304f91d-148a-4fea-cc96-b9972af617ab"
      },
      "cell_type": "code",
      "source": [
        "sent_count = 0\n",
        "for s_start, s_finish in PunktSentenceTokenizer().span_tokenize(report):\n",
        "    print(\"Sentence \" + str(sent_count) +\": \" + str([s_start, s_finish]))\n",
        "    print(report[s_start:s_finish].replace('\\n',' '))\n",
        "    print()\n",
        "    sent_count = sent_count + 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence 0: [0, 407]\n",
            "[**2176-7-10**] 5:34 AM  CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 29270**]  Reason: eval for CHF/ pulmonary edema  ______________________________________________________________________________  [**Hospital 4**] MEDICAL CONDITION:   83 year old woman with infected pseudocyst in pancreas, now altered mental   status, bilateral crackles new at bases.\n",
            "\n",
            "Sentence 1: [409, 628]\n",
            "REASON FOR THIS EXAMINATION:   eval for CHF/ pulmonary edema  ______________________________________________________________________________                                  FINAL REPORT  INDICATION:  Rectal pseudocyst.\n",
            "\n",
            "Sentence 2: [629, 651]\n",
            "Altered mental status.\n",
            "\n",
            "Sentence 3: [654, 732]\n",
            "SINGLE VIEW CHEST:   Comparison is made to prior radiograph of [**2176-7-7**].\n",
            "\n",
            "Sentence 4: [735, 786]\n",
            "A central venous line catheter is in the upper SVC.\n",
            "\n",
            "Sentence 5: [788, 876]\n",
            "There has been interval  placement of an NG tube which is seen to course to the stomach.\n",
            "\n",
            "Sentence 6: [878, 951]\n",
            "Again  demonstrated is a calcified plaque in the left lateral hemithorax.\n",
            "\n",
            "Sentence 7: [953, 1022]\n",
            "There is  bilateral basilar atelectasis and a right pleural effusion.\n",
            "\n",
            "Sentence 8: [1024, 1045]\n",
            "The lungs are  clear.\n",
            "\n",
            "Sentence 9: [1047, 1087]\n",
            "There is mild upper zone redistribution.\n",
            "\n",
            "Sentence 10: [1090, 1137]\n",
            "IMPRESSION:  1) Mild upper zone redistribution.\n",
            "\n",
            "Sentence 11: [1139, 1156]\n",
            "No overt failure.\n",
            "\n",
            "Sentence 12: [1158, 1203]\n",
            "2) Right effusion with bilateral atelectasis.\n",
            "\n",
            "Sentence 13: [1205, 1254]\n",
            "3) Densely calcified left lateral pleural plaque.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I4XRba2RsX8Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Spot occurrence(s) of word(s) related to your concept in a sentence or document"
      ]
    },
    {
      "metadata": {
        "id": "t8FOZQz7sX8T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Simple spotter: Spot occurrence of a term in a given lexicon anywhere within a text document or sentence:\n",
        "def spotter(text, lexicon):\n",
        "    text = text.lower()\n",
        "    # Spot if a document mentions any of the terms in the lexicon (not worrying about negation detection yet)\n",
        "    match = [x in text for x in lexicon]\n",
        "    if any(match) == True:\n",
        "        mentioned = 1\n",
        "    else:\n",
        "        mentioned = 0\n",
        "    return mentioned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2klc13vsX8b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Where the lexicon is a list of word(s) or phrase(s) refering to a concept of interest to you, e.g.\n",
        "ptx = ['pneumothorax', 'ptx']\n",
        "sent1 = 'Large left apical ptx present.'\n",
        "sent2 = 'Hello world for NLP'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrGoOz2rsX8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "600262c1-9fd6-4f9b-aaba-475c45fab1ea"
      },
      "cell_type": "code",
      "source": [
        "# lexicon mentioned in text, spotter return 1 (yes)\n",
        "spotter(sent1, ptx)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "mv8L6YgJsX8z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ddee49b-d0ba-4024-8233-e2fcd266014d"
      },
      "cell_type": "code",
      "source": [
        "# lexicon not mentioned in text, spotter return 0 (no)\n",
        "spotter(sent2, ptx)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "DjY1RsVxsX87",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**How can we do better?**\n",
        "We can do the spotting of concepts (lexicons) A LOT better (more sensitive) if we curate a list of all the ways that the concept could be expressed in raw text. This is what the NLP tool can help you achieve."
      ]
    },
    {
      "metadata": {
        "id": "jdGA0_RCsX88",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download a lexicon from the NLP tool:"
      ]
    },
    {
      "metadata": {
        "id": "MxCveXnLsX8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "# Enter your team's username between the quotation marks:\n",
        "user = \"team1\"\n",
        "# Enter your team's password\n",
        "#password = getpass.getpass()\n",
        "# If the above doesn't work, then comment out the password variable above and hard code your team's password below:\n",
        "password = '(send reforms capture  teams password)'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k0DikGGAsX9G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is the id of the lexicon - you can see it in the URL line when you are working with the lexicon\n",
        "# For example, for pneumothorax, it is:\n",
        "oid = \".2.48\"\n",
        "# You can do this in a loop to download all relevant lexicons into a data format you prefer too"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urOKwOq8sX9M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Don't spam with insecure warnings - some machines do not have all signing authority\n",
        "# root certificates preinstalled\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ttoSeI6VsX9R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The endpoints for the REST\n",
        "host = \"https://dla.sl.res.ibm.com\"\n",
        "lexurl = host + \"/oid\" + oid.replace('.', '/')\n",
        "quartermaster =  host + \"/search\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "k8K_mXhCsX9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "0facc401-aca4-43b3-b71a-64e2d1ba604b"
      },
      "cell_type": "code",
      "source": [
        "# Set up auth and get the lexicon. Then pull the terms out and lower case them\n",
        "auth=(user,password)\n",
        "lex = requests.get(lexurl, verify=False, auth=auth).json()\n",
        "terms = list(map(lambda x: x[\"surfaceForm\"].lower(), lex[\"members\"]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a4283754c109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"surfaceForm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"members\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "U0b-NKqesX9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "1e136990-56ac-475e-99bf-9503f973cd04"
      },
      "cell_type": "code",
      "source": [
        "# Printing out the pneumothorax lexicon (after 5 minutes of curating work on the NLP tool)\n",
        "ptx = terms.copy()\n",
        "print(ptx)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-73ff46f95d75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mptx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'terms' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "te2F6evWsX9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Negation detection"
      ]
    },
    {
      "metadata": {
        "id": "F4WUjy4LsX9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8af78947-93c1-4a74-9193-60cb15ecddce"
      },
      "cell_type": "code",
      "source": [
        "# But it's not enough to just spot word occurrences to determine if a concept is affirmative (positive/present) or not.\n",
        "\n",
        "# e.g. lexicon mentioned in text but negated, a simple spotter would still return 1 (yes)\n",
        "sent3 = 'Pneumothorax has resolved.'\n",
        "spotter(sent3, ptx)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "gdD6dxLMsX99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77f2fcd2-a7bd-4387-fc74-55acb4ae3637"
      },
      "cell_type": "code",
      "source": [
        "# However, if negation related words occur in close proximity (e.g. same sentence) to a spotted concept \n",
        "# Then we can right some rules to determine if the concept was negated or not\n",
        "\n",
        "# e.g. spotting negation words in the same sentence:\n",
        "neg = ['no','never','not','removed', 'ruled out', 'resolved']\n",
        "spotter(sent3, neg)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "TIf0l1nmsX-G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using off-the-shelf python library for negation, e.g. Negex"
      ]
    },
    {
      "metadata": {
        "id": "weCXERm6yjGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "824d8910-d702-469c-a59f-f20e2c82d9df"
      },
      "cell_type": "code",
      "source": [
        "#This downloads a copy of negex.py and negex_triggers.txt into this environment, we will learn how to use this in the next block\n",
        "!wget  https://stuff.mit.edu/~cwc76/hst953/negex.py\n",
        "!wget  https://stuff.mit.edu/~cwc76/hst953/negex_triggers.txt\n",
        "  \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-12 15:57:12--  https://stuff.mit.edu/~cwc76/hst953/negex.py\n",
            "Resolving stuff.mit.edu (stuff.mit.edu)... 18.4.60.31\n",
            "Connecting to stuff.mit.edu (stuff.mit.edu)|18.4.60.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8984 (8.8K) [text/x-python]\n",
            "Saving to: ‘negex.py’\n",
            "\n",
            "\rnegex.py              0%[                    ]       0  --.-KB/s               \rnegex.py            100%[===================>]   8.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-10-12 15:57:12 (137 MB/s) - ‘negex.py’ saved [8984/8984]\n",
            "\n",
            "--2018-10-12 15:57:13--  https://stuff.mit.edu/~cwc76/hst953/negex_triggers.txt\n",
            "Resolving stuff.mit.edu (stuff.mit.edu)... 18.4.60.31\n",
            "Connecting to stuff.mit.edu (stuff.mit.edu)|18.4.60.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7363 (7.2K) [text/plain]\n",
            "Saving to: ‘negex_triggers.txt’\n",
            "\n",
            "negex_triggers.txt  100%[===================>]   7.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-10-12 15:57:14 (224 MB/s) - ‘negex_triggers.txt’ saved [7363/7363]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lH7ofx7csX-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29fdcaaf-469f-4a5f-c404-9e43c878966f"
      },
      "cell_type": "code",
      "source": [
        "import negex\n",
        "rfile = open(r'negex_triggers.txt')\n",
        "irules = negex.sortRules(rfile.readlines())\n",
        "rfile.close()\n",
        "\n",
        "# Example:\n",
        "sent = \"There is no evidence of ptx.\"\n",
        "ptx = ['pneumothorax', 'ptx']\n",
        "tagger = negex.negTagger(sentence = sent, phrases = ptx, rules = irules, negP=False)\n",
        "negation = tagger.getNegationFlag()\n",
        "negation"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negated'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "c4SH4MWFsX-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "d0e7b8cd-be3d-4ffc-c134-df2824c4e287"
      },
      "cell_type": "code",
      "source": [
        "# Applying Negex to the first note:\n",
        "# Specify the lexicon of interest (\"phrases\" for Negex)\n",
        "ptx = terms.copy()\n",
        "# Get a randome note from the dataset:\n",
        "note = CXRreports['text'][random.randint(0,1000)]\n",
        "# Tokenize the sentences:\n",
        "sents = sent_tokenize(note.replace('\\n',' ')) # replacing new line breaks\n",
        "# Applying spotter function to each sentence:\n",
        "#neg_output = []\n",
        "count = 0\n",
        "for sent in sents:\n",
        "    # Apply Negex if a term in the ptx lexicon is spotted\n",
        "    if spotter(sent,ptx) == 1:\n",
        "        tagger = negex.negTagger(sentence = sent, phrases = ptx, rules = irules, negP=False)\n",
        "        negation = tagger.getNegationFlag()\n",
        "        #neg_output.append(negation)\n",
        "        print(\"Sentence \" + str(count) + \":\\n\" + sent + \"\\nNegex output: \" + negation + '\\n')\n",
        "        count = count + 1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5407f7fde854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mptx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Get a randome note from the dataset:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCXRreports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Tokenize the sentences:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# replacing new line breaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'terms' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "CLsQFv0qsX-U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Show the relevant CXR report for the analysis\n",
        "print(note)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTK33byysX-a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise for you:\n",
        "\n",
        "You can use similar/improved pipeline to loop through all the notes in your dataset and through different concepts/lexicons!"
      ]
    },
    {
      "metadata": {
        "id": "cMg45S-HsX-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTrozTq7sX-o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vqJmlOkAsX-s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IZwZ6kV-sX-v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}